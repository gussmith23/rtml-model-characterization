{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data on Relay Models for Guiding Hardware Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(f\"Last updated {datetime.now():%Y-%m-%d %H:%M:%S%z}.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.relay import analysis_tools\n",
    "import pandas as pd\n",
    "from tvm.relay.testing import mlp\n",
    "from tvm.relay.testing import resnet\n",
    "from tvm.relay.testing import dqn\n",
    "from tvm.relay.testing import dcgan\n",
    "from tvm.relay.testing import mobilenet\n",
    "from tvm.relay.testing import lstm\n",
    "from tvm.relay.testing import inception_v3\n",
    "from tvm.relay.testing import squeezenet\n",
    "from tvm.relay.testing import vgg\n",
    "from tvm.relay.testing import densenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't truncate Pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetReadableName(analysis_tools.AnalysisPass):\n",
    "    def visit_call(self, call):\n",
    "        super().visit_call(call)\n",
    "        self._add_detail(call, readable_name=call.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetIndex(analysis_tools.AnalysisPass):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.__id = 0\n",
    "\n",
    "    def visit_call(self, call):\n",
    "        super().visit_call(call)\n",
    "        self._add_detail(call, id=self.__id)\n",
    "        self.__id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizeOpTypes(relay.analysis_tools.AnalysisPass):\n",
    "    \"\"\"Requires GetReadableName analysis to run first.\"\"\"\n",
    "\n",
    "    def _summarize(self):\n",
    "        histogram = {}\n",
    "        for node, data in self._existing_data.items():\n",
    "            if data[\"readable_name\"] not in histogram:\n",
    "                histogram[data[\"readable_name\"]] = 1\n",
    "            else:\n",
    "                histogram[data[\"readable_name\"]] += 1\n",
    "        self._add_summary(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_shape(t):\n",
    "    if isinstance(t, relay.TensorType):\n",
    "        return [int(v) for v in t.shape]\n",
    "    elif isinstance(t, relay.TupleType):\n",
    "        return tuple(_extract_shape(u) for u in t.fields)\n",
    "    else:\n",
    "        import sys\n",
    "\n",
    "        print(\"Unhandled type \" + str(type(t)), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputShape(relay.analysis_tools.AnalysisPass):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def visit_call(self, call):\n",
    "        super().visit_call(call)\n",
    "        t = call.checked_type\n",
    "        self._add_detail(call, shape=_extract_shape(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputShapes(relay.analysis_tools.AnalysisPass):\n",
    "    \"\"\"Requires OutputShape analysis to run first.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def visit_call(self, call):\n",
    "        super().visit_call(call)\n",
    "        input_arg_analysis_data = {}\n",
    "        for i, arg in enumerate(call.args):\n",
    "            input_arg_analysis_data[i] = _extract_shape(arg.checked_type)\n",
    "        self._add_detail(call, input_shapes=input_arg_analysis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = {}\n",
    "results = {}\n",
    "summary_columns = set()\n",
    "for (module, _), name in [\n",
    "    (resnet.get_workload(num_layers=18), \"resnet18\"),\n",
    "    (resnet.get_workload(num_layers=50), \"resnet50\"),\n",
    "    (mobilenet.get_workload(), \"mobilenet\"),\n",
    "    (mlp.get_workload(batch_size=1), \"mlp\"),\n",
    "    (dqn.get_workload(batch_size=1), \"dqn\"),\n",
    "    (dcgan.get_workload(batch_size=1), \"dcgan\"),\n",
    "    # LSTM throws an error w/ analysis framework\n",
    "    #    (lstm.get_workload(iterations=32, num_hidden=32), 'lstm'),\n",
    "    (inception_v3.get_workload(), \"inception_v3\"),\n",
    "    (squeezenet.get_workload(), \"squeezenet\"),\n",
    "    (vgg.get_workload(batch_size=1), \"vgg\"),\n",
    "    (densenet.get_workload(), \"densenet\"),\n",
    "]:\n",
    "\n",
    "    # Simplify model for inference, which replaces batch norms\n",
    "    # with their component operations (add, sqrt, etc)\n",
    "    module = relay.transform.SimplifyInference()(module)\n",
    "\n",
    "    program = module[\"main\"]\n",
    "    analyses = [\n",
    "        GetReadableName(),\n",
    "        GetIndex(),\n",
    "        SummarizeOpTypes(),\n",
    "        OutputShape(),\n",
    "        InputShapes(),\n",
    "    ]\n",
    "    these_results, summary_results = relay.analysis_tools.run_analyses(\n",
    "        program, analyses\n",
    "    )\n",
    "    summary_columns.update(relay.analysis_tools.get_summary_columns(summary_results))\n",
    "    summaries[name] = summary_results\n",
    "    results[name] = these_results\n",
    "\n",
    "summary_columns_ordered = sorted(list(summary_columns))\n",
    "summary_column_names = list(map(lambda t: t[0], summary_columns_ordered))\n",
    "summary_records = list(\n",
    "    map(\n",
    "        lambda t: (t[0],)\n",
    "        + analysis_tools.summary_to_record(summary_columns_ordered, t[1]),\n",
    "        summaries.items(),\n",
    "    )\n",
    ")\n",
    "\n",
    "models_and_operators = pd.DataFrame.from_records(\n",
    "    summary_records, columns=[\"model\"] + summary_column_names, index=\"model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it look nicer by replacing NaNs.\n",
    "models_and_operators = models_and_operators.fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary table, comparing data across multiple networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, these_results in results.items():\n",
    "    # Contains (column_id, column_name) pairs.\n",
    "    columns = [\n",
    "        ((\"id\",), \"layer #\"),\n",
    "        ((\"readable_name\",), \"op in this layer\"),\n",
    "        ((\"shape\",), \"output shape\"),\n",
    "        ((\"input_shapes\", 0), \"input 0 shape\"),\n",
    "        ((\"input_shapes\", 1), \"input 1 shape\"),\n",
    "    ]\n",
    "    # Unzipping for later use\n",
    "    column_ids = [t[0] for t in columns]\n",
    "    column_names = [t[1] for t in columns]\n",
    "\n",
    "    for column in relay.analysis_tools.get_analysis_columns(these_results):\n",
    "        if column not in column_ids:\n",
    "            import sys\n",
    "\n",
    "            print(\n",
    "                \"Warning: missing column \" + str(column) + \", is this intentional?\",\n",
    "                file=sys.stderr,\n",
    "            )\n",
    "\n",
    "    as_records = relay.analysis_tools.get_records(these_results, column_ids)\n",
    "\n",
    "    df = pd.DataFrame.from_records(as_records, columns=column_names, index=\"layer #\")\n",
    "\n",
    "    # Make output prettier\n",
    "    df = df.fillna(value=\"\")\n",
    "\n",
    "    from IPython.display import display, Markdown\n",
    "\n",
    "    display(Markdown(f\"### {name}\"))\n",
    "    display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "465b2f5926d1c430d1fef595e1cd54f249b1e52a9f8018c8a8286b90565623c1"
   }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}